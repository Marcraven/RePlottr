{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "# Functions to generate simple plots\n",
        "\n",
        "\n",
        "def create_scatterplot_with_coco_bounding_boxes(num_points=10, size=(256, 256), dot_size=3):\n",
        "    # Initialize an image with ones (white)\n",
        "    image = np.ones((size[0], size[1], 3), dtype=np.uint8) * 255\n",
        "\n",
        "    # Generate random points\n",
        "    points = np.random.randint(0, size[0], size=(num_points, 2))\n",
        "\n",
        "    # Bounding boxes list\n",
        "    bounding_boxes = []\n",
        "\n",
        "    # Drawing points on the image and creating bounding boxes\n",
        "    for point in points:\n",
        "        x, y = point\n",
        "        # Draw a bigger dot\n",
        "        image[y-dot_size:y+dot_size+1, x-dot_size:x+dot_size+1] = [0, 0, 0]  # Black point\n",
        "\n",
        "        # Bounding box for each point (in COCO format)\n",
        "        bb_width = bb_height = 2 * dot_size\n",
        "        x_center = x / size[0]\n",
        "        y_center = y / size[1]\n",
        "        width_normalized = bb_width / size[0]\n",
        "        height_normalized = bb_height / size[1]\n",
        "\n",
        "        bounding_box = (x_center, y_center, width_normalized, height_normalized)\n",
        "        bounding_boxes.append(bounding_box)\n",
        "\n",
        "    return image, bounding_boxes\n",
        "\n",
        "def save_coco_bounding_boxes_to_txt(bounding_boxes, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        for box in bounding_boxes:\n",
        "            x_center, y_center, width, height = box\n",
        "            x1 = x_center - width / 2\n",
        "            y1 = y_center - height / 2\n",
        "            x2 = x_center + width / 2\n",
        "            y2 = y_center + height / 2\n",
        "            file.write(f'0 {x1} {y1} {width} {height}\\n')\n",
        "\n",
        "def read_coco_bounding_boxes_from_txt(filename):\n",
        "    bounding_boxes = []\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            data = line.strip().split()\n",
        "            category_id = int(data[0])\n",
        "            x1, y1, width, height = map(float, data[1:])\n",
        "            x_center = x1 + width / 2\n",
        "            y_center = y1 + height / 2\n",
        "            bounding_box = (x_center, y_center, width, height)\n",
        "            bounding_boxes.append(bounding_box)\n",
        "    return bounding_boxes\n",
        "\n",
        "def visualize_coco_bounding_boxes(image, bounding_boxes, size=(256, 256)):\n",
        "    # Iterate over the bounding boxes and draw them\n",
        "    for box in bounding_boxes:\n",
        "        x_center, y_center, width, height = box\n",
        "        x_center *= size[0]\n",
        "        y_center *= size[1]\n",
        "        width *= size[0]\n",
        "        height *= size[1]\n",
        "\n",
        "        # Convert COCO format to top-left and bottom-right coordinates\n",
        "        x1 = int(x_center - width / 2)\n",
        "        y1 = int(y_center - height / 2)\n",
        "        x2 = int(x_center + width / 2)\n",
        "        y2 = int(y_center + height / 2)\n",
        "\n",
        "        # Draw rectangle (bounding box)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 1)  # Red box\n",
        "\n",
        "    return image\n",
        "\n",
        "# Generate image and bounding boxes\n",
        "scatter_image, coco_boxes = create_scatterplot_with_coco_bounding_boxes()\n",
        "\n",
        "# # Save the generated image\n",
        "# image_path = 'scatterplot.png'\n",
        "# cv2.imwrite(image_path, scatter_image)\n",
        "\n",
        "# # Save the bounding boxes to a text file in COCO format\n",
        "# bounding_boxes_path = 'bounding_boxes.txt'\n",
        "# save_coco_bounding_boxes_to_txt(coco_boxes, bounding_boxes_path)\n",
        "\n",
        "# # Read the image and bounding box information from the files\n",
        "# loaded_image = cv2.imread(image_path)\n",
        "# loaded_coco_boxes = read_coco_bounding_boxes_from_txt(bounding_boxes_path)\n",
        "\n",
        "# # Visualize the bounding boxes on the loaded image\n",
        "# visualized_image = visualize_coco_bounding_boxes(loaded_image.copy(), loaded_coco_boxes)\n",
        "\n",
        "# # Display or save the visualized image\n",
        "# visualized_image_path = 'visualized_coco_scatterplot.png'\n",
        "# cv2.imwrite(visualized_image_path, visualized_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create folders to fill in with data\n",
        "import os\n",
        "base_dir='yolo'\n",
        "dirs =  ['train', 'test', 'val']\n",
        "for subset in dirs:\n",
        "    img_dir = os.path.join(base_dir, 'images', subset)\n",
        "    label_dir = os.path.join(base_dir, 'labels', subset)\n",
        "    os.makedirs(img_dir, exist_ok=True)\n",
        "    os.makedirs(label_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "# Train the model with Ultralytics - wrap around of Pytorch Yolo model\n",
        "# yolov8s-p2 - version for detecting smaller objects on images\n",
        "# https://github.com/ultralytics/ultralytics/issues/981  - you can find out more here\n",
        "def train_model():\n",
        "    # Load the pre-trained model\n",
        "    model = YOLO(\"yolov8s-p2.yaml\").load(\"yolov8s.pt\")\n",
        "\n",
        "    # Train the model\n",
        "    model.train(\n",
        "        data=\"dataset.yaml\", epochs=200,  imgsz=320, save=True, format='onnx'\n",
        "    )  # Set imgsz to 320 for training on 320xsomething images\n",
        "\n",
        "    # Export the model to ONNX format\n",
        "    path = model.export()\n",
        "    print(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# I WOULD HIGHLY RECCOMEND TRAINING USING COMET (its like MLFLOW)\n",
        "# https://docs.ultralytics.com/modes/train/#logging - HOW TO\n",
        "# you will have all the weights and training progress save there inside of experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 17             [-1, 2]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 19                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 20            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 22                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 23            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 24                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 26             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 27                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 28    [18, 21, 24, 27]  1   1666896  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256, 512]]     \n",
            "YOLOv8s-p2 summary: 277 layers, 10884336 parameters, 10884320 gradients, 39.7 GFLOPs\n",
            "\n",
            "Transferred 219/437 items from pretrained weights\n",
            "Ultralytics YOLOv8.0.219 üöÄ Python-3.10.6 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s-p2.yaml, data=dataset.yaml, epochs=200, patience=50, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=onnx, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/root/.pyenv/runs/detect/train15\n",
            "Overriding model.yaml nc=80 with nc=21\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 17             [-1, 2]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 19                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 20            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 22                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 23            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 24                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 26             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 27                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 28    [18, 21, 24, 27]  1   1424996  ultralytics.nn.modules.head.Detect           [21, [64, 128, 256, 512]]     \n",
            "YOLOv8s-p2 summary: 277 layers, 10642436 parameters, 10642420 gradients, 37.0 GFLOPs\n",
            "\n",
            "Transferred 389/437 items from pretrained weights\n",
            "WARNING ‚ö†Ô∏è Comet installed but not initialized correctly, not logging this run. Comet.ml requires an API key. Please provide as the first argument to Experiment(api_key) or as an environment variable named COMET_API_KEY \n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /root/.pyenv/runs/detect/train15', view at http://localhost:6006/\n",
            "Freezing layer 'model.28.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/code/marcraven/DonutPlot/ObjectRecognition/yolo/dataset/train... 100 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 414.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /root/code/marcraven/DonutPlot/ObjectRecognition/yolo/dataset/train.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /root/code/marcraven/DonutPlot/ObjectRecognition/yolo/dataset/validation... 12 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 416.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /root/code/marcraven/DonutPlot/ObjectRecognition/yolo/dataset/validation.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /root/.pyenv/runs/detect/train15/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0004, momentum=0.9) with parameter groups 70 weight(decay=0.0), 79 weight(decay=0.0005), 78 bias(decay=0.0)\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/root/.pyenv/runs/detect/train15\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/200      2.81G      5.517      5.839      4.202         78        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:38<00:00,  5.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         12        277          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/200      2.24G      5.362       5.82      4.174        140        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         12        277          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/200      2.17G      5.262      5.805      4.104        132        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         12        277          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/200      2.59G      5.462      5.785       4.04        158        320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:03<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         12        277          0          0          0          0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/root/code/marcraven/DonutPlot/ObjectRecognition/Train simple YOLO model to detect scatter points.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_model()\n",
            "\u001b[1;32m/root/code/marcraven/DonutPlot/ObjectRecognition/Train simple YOLO model to detect scatter points.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m\"\u001b[39m\u001b[39myolov8s-p2.yaml\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39myolov8s.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdataset.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,  imgsz\u001b[39m=\u001b[39;49m\u001b[39m320\u001b[39;49m, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39monnx\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m )  \u001b[39m# Set imgsz to 320 for training on 320xsomething images\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Export the model to ONNX format\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m path \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mexport()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/model.py:338\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    339\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/trainer.py:190\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/trainer.py:385\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[39m# Save model\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave \u001b[39mor\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n\u001b[0;32m--> 385\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_model()\n\u001b[1;32m    386\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks(\u001b[39m'\u001b[39m\u001b[39mon_model_save\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    388\u001b[0m tnow \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/trainer.py:423\u001b[0m, in \u001b[0;36mBaseTrainer.save_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m metrics \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mfitness\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness}}\n\u001b[1;32m    418\u001b[0m results \u001b[39m=\u001b[39m {k\u001b[39m.\u001b[39mstrip(): v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcsv)\u001b[39m.\u001b[39mto_dict(orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m ckpt \u001b[39m=\u001b[39m {\n\u001b[1;32m    420\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch,\n\u001b[1;32m    421\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbest_fitness\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_fitness,\n\u001b[1;32m    422\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: deepcopy(de_parallel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel))\u001b[39m.\u001b[39mhalf(),\n\u001b[0;32m--> 423\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mema\u001b[39m\u001b[39m'\u001b[39m: deepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mema\u001b[39m.\u001b[39;49mema)\u001b[39m.\u001b[39mhalf(),\n\u001b[1;32m    424\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mupdates\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mema\u001b[39m.\u001b[39mupdates,\n\u001b[1;32m    425\u001b[0m     \u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstate_dict(),\n\u001b[1;32m    426\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain_args\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mvars\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs),  \u001b[39m# save as dict\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain_metrics\u001b[39m\u001b[39m'\u001b[39m: metrics,\n\u001b[1;32m    428\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain_results\u001b[39m\u001b[39m'\u001b[39m: results,\n\u001b[1;32m    429\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m: datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39misoformat(),\n\u001b[1;32m    430\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m'\u001b[39m: __version__}\n\u001b[1;32m    432\u001b[0m \u001b[39m# Save last and best\u001b[39;00m\n\u001b[1;32m    433\u001b[0m torch\u001b[39m.\u001b[39msave(ckpt, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:297\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dictiter:\n\u001b[1;32m    296\u001b[0m         key \u001b[39m=\u001b[39m deepcopy(key, memo)\n\u001b[0;32m--> 297\u001b[0m         value \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    298\u001b[0m         y[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m    299\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "    \u001b[0;31m[... skipping similar frames: deepcopy at line 172 (1 times)]\u001b[0m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
            "    \u001b[0;31m[... skipping similar frames: deepcopy at line 172 (1 times)]\u001b[0m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:297\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dictiter:\n\u001b[1;32m    296\u001b[0m         key \u001b[39m=\u001b[39m deepcopy(key, memo)\n\u001b[0;32m--> 297\u001b[0m         value \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    298\u001b[0m         y[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m    299\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "    \u001b[0;31m[... skipping similar frames: deepcopy at line 172 (9 times), _deepcopy_dict at line 231 (4 times), _reconstruct at line 271 (4 times), _reconstruct at line 297 (4 times), deepcopy at line 146 (4 times)]\u001b[0m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:297\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dictiter:\n\u001b[1;32m    296\u001b[0m         key \u001b[39m=\u001b[39m deepcopy(key, memo)\n\u001b[0;32m--> 297\u001b[0m         value \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    298\u001b[0m         y[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m    299\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/torch/nn/parameter.py:58\u001b[0m, in \u001b[0;36mParameter.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m memo[\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)]\n\u001b[1;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mclone(memory_format\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpreserve_format), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequires_grad)\n\u001b[1;32m     59\u001b[0m     memo[\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)] \u001b[39m=\u001b[39m result\n\u001b[1;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best-30.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train simple YOLO model to detect scatter points.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example of predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39multralytics\u001b[39;00m \u001b[39mimport\u001b[39;00m YOLO\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m'\u001b[39;49m\u001b[39mbest-30.pt\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# Load this from\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m model(\u001b[39m'\u001b[39m\u001b[39mObjectRecognition/yolo/dataset/test/0000.jpg\u001b[39m\u001b[39m'\u001b[39m, imgsz\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, conf\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/model.py:94\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(model, task)\n\u001b[1;32m     93\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load(model, task)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/model.py:146\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    144\u001b[0m suffix \u001b[39m=\u001b[39m Path(weights)\u001b[39m.\u001b[39msuffix\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m suffix \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt \u001b[39m=\u001b[39m attempt_load_one_weight(weights)\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverrides \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset_ckpt_args(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39margs)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/nn/tasks.py:628\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mattempt_load_one_weight\u001b[39m(weight, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fuse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    627\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m     ckpt, weight \u001b[39m=\u001b[39m torch_safe_load(weight)  \u001b[39m# load ckpt\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mDEFAULT_CFG_DICT, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(ckpt\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtrain_args\u001b[39m\u001b[39m'\u001b[39m, {}))}  \u001b[39m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     model \u001b[39m=\u001b[39m (ckpt\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mema\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m ckpt[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat()  \u001b[39m# FP32 model\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/nn/tasks.py:567\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[39mwith\u001b[39;00m temporary_modules({\n\u001b[1;32m    564\u001b[0m             \u001b[39m'\u001b[39m\u001b[39multralytics.yolo.utils\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39multralytics.utils\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    565\u001b[0m             \u001b[39m'\u001b[39m\u001b[39multralytics.yolo.v8\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39multralytics.models.yolo\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    566\u001b[0m             \u001b[39m'\u001b[39m\u001b[39multralytics.yolo.data\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39multralytics.data\u001b[39m\u001b[39m'\u001b[39m}):  \u001b[39m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(file, map_location\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m), file  \u001b[39m# load\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best-30.pt'"
          ]
        }
      ],
      "source": [
        "# Example of predictions\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('best-30.pt') # Load this from\n",
        "results = model('ObjectRecognition/yolo/dataset/test/0000.jpg', imgsz=256, save=True, conf=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lewagon",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
